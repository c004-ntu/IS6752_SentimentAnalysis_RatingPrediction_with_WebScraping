{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Scraping Movie Ratings </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites:\n",
    "* Make sure to place chromedriver.exe in the same directory as your code, in \"\\chromedriver-win64\" subfolder.\n",
    "* Make sure you have mysql installed. \n",
    "* Make sure you have a database named \"scraping\". Otherwise, execute this command.\n",
    "<br>CREATE DATABASE scraping;\n",
    "* Make sure you have table named \"movie\" in scraping database. Otherwise, execute this command.\n",
    "<br>\n",
    "<span style=\"color:green;\">CREATE TABLE movie (movieid VARCHAR(255) PRIMARY KEY, movie_title VARCHAR(255), movie_year INT, movie_release_date DATE, movie_genre VARCHAR(255), movie_rating INT, movie_href VARCHAR(255), movie_desc TEXT, movie_cast TEXT, movie_tag TEXT, budget DECIMAL(15, 2), revenue DECIMAL(15, 2), page_count INT, download_flag INT);</span>\n",
    "* Make sure you have table named \"rating\" in scraping database. Otherwise, execute this command.\n",
    "<br>\n",
    "<span style=\"color:green;\">CREATE TABLE rating (reviewid VARCHAR(255) PRIMARY KEY, userid VARCHAR(255), movieid VARCHAR(255), movie_title VARCHAR(255), rating INT, review_date DATE, review_text TEXT, user_href VARCHAR(255), review_href VARCHAR(255), download_flag INT);</span>\n",
    "* Make sure you have table named \"user\" in scraping database. Otherwise, execute this command.\n",
    "<br>\n",
    "<span style=\"color:green;\">CREATE TABLE user (userid VARCHAR(50) PRIMARY KEY, user_name VARCHAR(100), user_href VARCHAR(255), user_join_date DATE);</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5) # Wait for the page to load, also respecting TMDB rate limit: 40 request per 10 seconds\n",
    "    bsObj = BeautifulSoup(driver.page_source, 'lxml') # Get the page source and parse it with Beautiful Soup\n",
    "    return bsObj\n",
    "\n",
    "def download_Ratings (driver, conn, cur, main_url):\n",
    "    \n",
    "    sub_url = \"/reviews\"\n",
    "    count = 0\n",
    "\n",
    "    reviewid = \"\"\n",
    "    userid = \"\"\n",
    "    movieid = \"\"\n",
    "    movie_title= \"\"\n",
    "    rating = \"\"\n",
    "    review_date = \"\"\n",
    "    review_text = \"\"\n",
    "    user_href = \"\"\n",
    "    review_href = \"\"\n",
    "    download_flag = 0\n",
    "\n",
    "    filtered_movie_df = select_movie (cur)\n",
    "    filtered_movie_df_len = len(filtered_movie_df)\n",
    "\n",
    "    progress_bar = tqdm(desc='Rating download progress for movie #', total=filtered_movie_df_len)  # progress bar\n",
    "\n",
    "    for index, row in filtered_movie_df.iterrows():\n",
    "        try:\n",
    "            url = main_url + row['movie_href'] + sub_url\n",
    "            # print(url)\n",
    "            movieid = row['movieid']\n",
    "            movie_title = re.sub(r\"['\\\"]\", r\"\\\\'\", row['movie_title'])\n",
    "            # print(movieid, movie_title)\n",
    "\n",
    "            # Open the page\n",
    "            bsObj = getPage(driver, url)\n",
    "\n",
    "            time.sleep(2)\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            # Find all review containers\n",
    "            div_info = bsObj.find_all('div', {\"class\":\"info\"})\n",
    "            # print(\"===========================================\")\n",
    "\n",
    "            if div_info:\n",
    "                for div in div_info:\n",
    "                    children = div.findChildren()\n",
    "                    for child in children:\n",
    "                        if child.name:\n",
    "\n",
    "                            if child.get('href') and '/review/' in child.get('href'):\n",
    "                                review_href = child.get('href')\n",
    "                                reviewid = review_href.replace('/review/', '')\n",
    "                                # print(reviewid, review_href)\n",
    "                            \n",
    "                            if child.get('href') and '/u/' in child.get('href'):\n",
    "                                user_href = child.get('href')\n",
    "                                userid = user_href.replace('/u/','')\n",
    "                                # print(user_href, userid)\n",
    "\n",
    "                            rating_tag = child.find('div', {\"class\": \"rating_border rating\"})\n",
    "                            if rating_tag:\n",
    "                                if rating_tag.get_text().strip()!='':\n",
    "                                    rating = re.sub('%','',rating_tag.get_text().strip())\n",
    "                                else:\n",
    "                                    rating=0\n",
    "                                # print('rating', rating)\n",
    "\n",
    "                            date_tag = child.find('h5')\n",
    "                            if date_tag:\n",
    "                                # review_date = re.search(r'(\\w+ \\d{0,2}, \\d{4})', date_tag.get_text().strip())\n",
    "                                review_date = ' '.join(date_tag.get_text().strip().split()[-3:])\n",
    "                                if review_date:\n",
    "                                    review_date = datetime.strptime(review_date, \"%B %d, %Y\").date()\n",
    "                                    review_date = review_date.strftime(\"%Y-%m-%d\")\n",
    "                                else:\n",
    "                                    review_date = '1900-01-01'\n",
    "                                    # print('review date', review_date)\n",
    "                                \n",
    "                    # Populate review text\n",
    "                    url_review = main_url + review_href\n",
    "                    bsObj_review = getPage(driver, url_review)\n",
    "                    div_review = bsObj_review.find('div',{'class':'content column pad'})\n",
    "\n",
    "                    if div_review:\n",
    "                        reviews = div_review.get_text(separator=\"|\", strip=True).split(\"|\")\n",
    "                        reviews = reviews[4:]\n",
    "                        review_text = ' '.join (reviews)\n",
    "                        review_text = re.sub(r\"['\\\"]\", r\"\\\\'\", review_text)\n",
    "\n",
    "                    # print(f'{reviewid}, {userid}, {movieid}, {movie_title}, {rating}, {review_date}, {review_text}, {user_href}, {review_href}, {download_flag}')\n",
    "                    # print(f'{movieid}, {review_href}')\n",
    "\n",
    "                    # Insert new record to database\n",
    "                    insert_update_rating_to_db(cur, reviewid, userid, movieid, movie_title, rating, review_date, review_text, user_href, review_href, download_flag)\n",
    "                    conn.commit()\n",
    "\n",
    "                    # Log entry to a text file in case of download stops due to reached limit\n",
    "                    with open('log_rating.txt', 'a') as file:\n",
    "                        file.write(f'{movieid}, {review_href}, {user_href}\\n')\n",
    "                    \n",
    "                    count +=1\n",
    "            \n",
    "            # Update download_flag in movie table. This is to address the daily request limit in TMDB. Only movies without rating will be downloaded in next session.\n",
    "            update_movie_downloadflag(cur, movieid)\n",
    "            conn.commit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {review_href}: {e}\")\n",
    "            print(f'{reviewid}, {userid}, {movieid}, {movie_title}, {rating}, {review_date}, {review_text}, {user_href}, {review_href}, {download_flag}')\n",
    "            continue\n",
    "\n",
    "    progress_bar.close()\n",
    "    \n",
    "    rating_df = select_all_rating (cur)\n",
    "\n",
    "    return rating_df\n",
    "\n",
    "def insert_update_rating_to_db (cursor, reviewid, userid, movieid, movie_title, rating, review_date, review_text, user_href, review_href, download_flag):\n",
    "    sql = '''\n",
    "    INSERT INTO rating (reviewid, userid, movieid, movie_title, rating, review_date, review_text, user_href, review_href, download_flag)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        userid = values(userid),\n",
    "        movieid = values(movieid),\n",
    "        movie_title = values(movie_title),\n",
    "        rating = values(rating),\n",
    "        review_date = values(review_date),\n",
    "        review_text = values(review_text),\n",
    "        user_href = values(user_href),\n",
    "        review_href = values(review_href);\n",
    "    '''\n",
    "    cursor.execute (\"USE scraping;\")\n",
    "    cursor.execute(sql, (reviewid, userid, movieid, movie_title, rating, review_date, review_text, user_href, review_href, download_flag))\n",
    "\n",
    "def select_all_movie (cursor):\n",
    "    cursor.execute (\"USE scraping;\")\n",
    "    cursor.execute(\"SELECT * from movie;\")\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    df_mysql = pd.DataFrame(rows, columns=columns)\n",
    "    return df_mysql\n",
    "\n",
    "def select_all_rating (cursor):\n",
    "    cursor.execute (\"USE scraping;\")\n",
    "    cursor.execute(\"SELECT * from rating;\")\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    df_mysql = pd.DataFrame(rows, columns=columns)\n",
    "    return df_mysql\n",
    "\n",
    "def select_movie (cursor):\n",
    "    cursor.execute (\"USE scraping;\")\n",
    "    cursor.execute(\"SELECT * from movie where download_flag = 0 or download_flag is null order by page_count, movieid;\")\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    df_mysql = pd.DataFrame(rows, columns=columns)\n",
    "    return df_mysql\n",
    "\n",
    "def update_movie_downloadflag (cursor, movieid):\n",
    "    sql = \"UPDATE movie SET download_flag = 1 where movieid ='\" + movieid + \"';\"\n",
    "    cursor.execute (\"USE scraping;\")\n",
    "    cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "main_url = \"https://www.themoviedb.org\"\n",
    "user_agent = {\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\"}\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless=new\")\n",
    "# chrome_options.add_argument(\"--window-position=-2400,-2400\") # hide window\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "chrome_options.add_argument(\"--disable-infobars\")\n",
    "chrome_options.add_argument(\"--disable-web-security\")\n",
    "chrome_options.add_argument(\"--disable-site-isolation-trials\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=BlockCredentialedSubresources\")\n",
    "chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "# Set up the WebDriver\n",
    "chrome_driver = os.getcwd() + \"\\\\chromedriver-win64\" + \"\\\\chromedriver.exe\"\n",
    "service = Service(chrome_driver)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Connect to database\n",
    "try:\n",
    "    conn = pymysql.connect(host='127.0.0.1', user='root', passwd='root', db='scraping')\n",
    "    cur = conn.cursor()\n",
    "    print(\"Connection successful!\")\n",
    "except pymysql.MySQLError as e:\n",
    "    print(f\"Error connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b86d2c651f14090989a9482d94b7035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rating download progress for movie #:   0%|          | 0/4796 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10468, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>user_href</th>\n",
       "      <th>review_href</th>\n",
       "      <th>download_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>67267f06554083a56a0d4e20</td>\n",
       "      <td>GenerationofSwine</td>\n",
       "      <td>9411-fallen</td>\n",
       "      <td>Fallen</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>I generally have a distaste for movies where D...</td>\n",
       "      <td>/u/GenerationofSwine</td>\n",
       "      <td>/review/67267f06554083a56a0d4e20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>672794d7c0bc0749d0d89f29</td>\n",
       "      <td>BiankaMalburg</td>\n",
       "      <td>1184918-the-wild-robot</td>\n",
       "      <td>The Wild Robot</td>\n",
       "      <td>90</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>Dreamworks at its best!!!! 😍😭❤️</td>\n",
       "      <td>/u/BiankaMalburg</td>\n",
       "      <td>/review/672794d7c0bc0749d0d89f29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       reviewid             userid                 movieid  \\\n",
       "10466  67267f06554083a56a0d4e20  GenerationofSwine             9411-fallen   \n",
       "10467  672794d7c0bc0749d0d89f29      BiankaMalburg  1184918-the-wild-robot   \n",
       "\n",
       "          movie_title  rating review_date  \\\n",
       "10466          Fallen       0  2024-11-02   \n",
       "10467  The Wild Robot      90  2024-11-03   \n",
       "\n",
       "                                             review_text  \\\n",
       "10466  I generally have a distaste for movies where D...   \n",
       "10467                    Dreamworks at its best!!!! 😍😭❤️   \n",
       "\n",
       "                  user_href                       review_href  download_flag  \n",
       "10466  /u/GenerationofSwine  /review/67267f06554083a56a0d4e20              0  \n",
       "10467      /u/BiankaMalburg  /review/672794d7c0bc0749d0d89f29              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_df = download_Ratings (driver, conn, cur, main_url)\n",
    "print(rating_df.shape)\n",
    "display(rating_df.tail(2))\n",
    "\n",
    "# Export movie to csv\n",
    "rating_df.to_csv(\"rating.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ChromiumDriver.quit of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"2675a55c5fd4e183112336a76c0b0c4e\")>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.close()\n",
    "conn.close()\n",
    "driver.close\n",
    "driver.quit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
